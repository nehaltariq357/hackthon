"use strict";(globalThis.webpackChunkai_robotics_textbook=globalThis.webpackChunkai_robotics_textbook||[]).push([[645],{2218:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>g,frontMatter:()=>r,metadata:()=>c,toc:()=>p});var a=s(4848),i=s(8453),t=s(1226),o=s(5783);const r={sidebar_position:2,title:"Isaac ROS Framework"},l="Isaac ROS Framework",c={id:"module-3-nvidia-isaac/topic-1",title:"Isaac ROS Framework",description:"Isaac ROS is NVIDIA's robotics platform that brings GPU acceleration and AI capabilities to ROS 2. It provides a collection of hardware-accelerated packages that enable robots to perceive, understand, and navigate the world around them.",source:"@site/docs/module-3-nvidia-isaac/topic-1.mdx",sourceDirName:"module-3-nvidia-isaac",slug:"/module-3-nvidia-isaac/topic-1",permalink:"/docs/module-3-nvidia-isaac/topic-1",draft:!1,unlisted:!1,editUrl:"https://github.com/nehaltariq357/hackthon/tree/master/docs/module-3-nvidia-isaac/topic-1.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Isaac ROS Framework"},sidebar:"textbookSidebar",previous:{title:"Module 3: NVIDIA Isaac AI Brain",permalink:"/docs/module-3-nvidia-isaac/"},next:{title:"AI Tools and Acceleration",permalink:"/docs/module-3-nvidia-isaac/topic-2"}},d={},p=[{value:"Overview of Isaac ROS",id:"overview-of-isaac-ros",level:2},{value:"Isaac ROS Installation and Setup",id:"isaac-ros-installation-and-setup",level:2},{value:"Hardware-Accelerated Perception Example",id:"hardware-accelerated-perception-example",level:2},{value:"Isaac ROS GEMs (GPU-accelerated Elements &amp; Modules)",id:"isaac-ros-gems-gpu-accelerated-elements--modules",level:2},{value:"Isaac ROS Navigation",id:"isaac-ros-navigation",level:2},{value:"Best Practices with Isaac ROS",id:"best-practices-with-isaac-ros",level:2},{value:"Summary",id:"summary",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(o.A,{}),"\n",(0,a.jsx)(n.h1,{id:"isaac-ros-framework",children:"Isaac ROS Framework"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS is NVIDIA's robotics platform that brings GPU acceleration and AI capabilities to ROS 2. It provides a collection of hardware-accelerated packages that enable robots to perceive, understand, and navigate the world around them."}),"\n",(0,a.jsx)(n.h2,{id:"overview-of-isaac-ros",children:"Overview of Isaac ROS"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS extends the ROS 2 ecosystem with:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hardware-accelerated packages"}),": GPU-accelerated perception and navigation algorithms"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Isaac ROS GEMs"}),": Reusable, modular components for common robotics tasks"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Integration with NVIDIA hardware"}),": Optimized for Jetson and RTX platforms"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"AI-powered capabilities"}),": Deep learning integration for perception and planning"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"isaac-ros-installation-and-setup",children:"Isaac ROS Installation and Setup"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",metastring:'title="install_isaac_ros.sh"',children:"#!/bin/bash\n\n# Add NVIDIA package repositories\ncurl -sSL https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3 get-pip.py\nsudo apt update\n\n# Install Isaac ROS packages\nsudo apt install -y ros-humble-isaac-ros-common\nsudo apt install -y ros-humble-isaac-ros-gems\nsudo apt install -y ros-humble-isaac-ros-perception\nsudo apt install -y ros-humble-isaac-ros-navigation\n"})}),"\n",(0,a.jsx)(n.h2,{id:"hardware-accelerated-perception-example",children:"Hardware-Accelerated Perception Example"}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of using Isaac ROS for stereo depth estimation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="isaac_stereo_node.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom stereo_msgs.msg import DisparityImage\nfrom cv_bridge import CvBridge\nimport numpy as np\nimport cv2\n\nclass IsaacStereoNode(Node):\n    def __init__(self):\n        super().__init__('isaac_stereo_node')\n\n        # Initialize CV Bridge\n        self.bridge = CvBridge()\n\n        # Publishers and subscribers\n        self.left_image_sub = self.create_subscription(\n            Image, 'left/image_rect', self.left_image_callback, 10)\n        self.right_image_sub = self.create_subscription(\n            Image, 'right/image_rect', self.right_image_callback, 10)\n\n        self.disparity_pub = self.create_publisher(\n            DisparityImage, 'disparity', 10)\n\n        # Stereo matching parameters\n        self.stereo = cv2.StereoSGBM_create(\n            minDisparity=0,\n            numDisparities=128,\n            blockSize=5,\n            P1=8 * 3 * 5**2,\n            P2=32 * 3 * 5**2,\n            disp12MaxDiff=1,\n            uniquenessRatio=15,\n            speckleWindowSize=0,\n            speckleRange=2,\n            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n        )\n\n        # Store images for stereo processing\n        self.left_image = None\n        self.right_image = None\n        self.latest_left = None\n        self.latest_right = None\n\n    def left_image_callback(self, msg):\n        \"\"\"Callback for left camera image\"\"\"\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='mono8')\n        self.latest_left = cv_image\n\n    def right_image_callback(self, msg):\n        \"\"\"Callback for right camera image\"\"\"\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='mono8')\n        self.latest_right = cv_image\n\n        # Process stereo pair if both images are available\n        if self.latest_left is not None and self.latest_right is not None:\n            self.process_stereo_pair()\n\n    def process_stereo_pair(self):\n        \"\"\"Process stereo image pair to generate disparity map\"\"\"\n        if self.latest_left is not None and self.latest_right is not None:\n            # Compute disparity using SGBM\n            disparity = self.stereo.compute(\n                self.latest_left, self.latest_right\n            ).astype(np.float32) / 16.0\n\n            # Create disparity message\n            disp_msg = DisparityImage()\n            disp_msg.header = self.get_clock().now().to_msg()\n            disp_msg.image = self.bridge.cv2_to_imgmsg(disparity, encoding='32FC1')\n            disp_msg.f = 525.0  # Focal length (example value)\n            disp_msg.T = 0.1  # Baseline (example value)\n\n            self.disparity_pub.publish(disp_msg)\n            self.get_logger().info('Published disparity image')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    isaac_stereo_node = IsaacStereoNode()\n\n    try:\n        rclpy.spin(isaac_stereo_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        isaac_stereo_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-ros-gems-gpu-accelerated-elements--modules",children:"Isaac ROS GEMs (GPU-accelerated Elements & Modules)"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS GEMs provide pre-built, GPU-accelerated components:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="isaac_ros_detection_pipeline.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nfrom cv_bridge import CvBridge\nimport jetson.inference\nimport jetson.utils\n\nclass IsaacObjectDetectionNode(Node):\n    def __init__(self):\n        super().__init__('isaac_object_detection_node')\n\n        # Initialize CV Bridge\n        self.bridge = CvBridge()\n\n        # Publishers and subscribers\n        self.image_sub = self.create_subscription(\n            Image, 'camera/image_raw', self.image_callback, 10)\n        self.detections_pub = self.create_publisher(\n            Detection2DArray, 'detections', 10)\n\n        # Load Isaac ROS detection model\n        # This would use NVIDIA's optimized inference engines\n        self.net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\n\n    def image_callback(self, msg):\n        \"\"\"Process image with Isaac ROS accelerated detection\"\"\"\n        # Convert ROS image to CUDA image\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n        cuda_image = jetson.utils.cudaFromNumpy(cv_image)\n\n        # Perform object detection using Isaac ROS accelerated model\n        detections = self.net.Detect(cuda_image)\n\n        # Convert detections to ROS message\n        detections_msg = Detection2DArray()\n        detections_msg.header = msg.header\n\n        for detection in detections:\n            # Create detection message\n            detection_msg = Detection2D()\n            detection_msg.header = msg.header\n\n            # Bounding box\n            bbox = BoundingBox2D()\n            bbox.center.position.x = detection.Center[0]\n            bbox.center.position.y = detection.Center[1]\n            bbox.size_x = detection.Width\n            bbox.size_y = detection.Height\n\n            detection_msg.bbox = bbox\n\n            # Results\n            result = ObjectHypothesisWithPose()\n            result.hypothesis.class_id = self.net.GetClassDesc(detection.ClassID)\n            result.hypothesis.score = detection.Confidence\n\n            detection_msg.results.append(result)\n            detections_msg.detections.append(detection_msg)\n\n        self.detections_pub.publish(detections_msg)\n        self.get_logger().info(f'Published {len(detections)} detections')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    detection_node = IsaacObjectDetectionNode()\n\n    try:\n        rclpy.spin(detection_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        detection_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-ros-navigation",children:"Isaac ROS Navigation"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS provides GPU-accelerated navigation capabilities:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="isaac_navigation_node.py"',children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom nav_msgs.msg import OccupancyGrid, Odometry\nfrom sensor_msgs.msg import LaserScan, PointCloud2\nimport numpy as np\n\nclass IsaacNavigationNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_navigation_node\')\n\n        # Publishers and subscribers\n        self.goal_sub = self.create_subscription(\n            PoseStamped, \'goal_pose\', self.goal_callback, 10)\n        self.odom_sub = self.create_subscription(\n            Odometry, \'odom\', self.odom_callback, 10)\n        self.scan_sub = self.create_subscription(\n            LaserScan, \'scan\', self.scan_callback, 10)\n        self.cmd_vel_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        # Navigation state\n        self.current_pose = None\n        self.goal_pose = None\n        self.map = None\n\n        # Timer for navigation loop\n        self.nav_timer = self.create_timer(0.1, self.navigation_loop)\n\n    def goal_callback(self, msg):\n        """Handle navigation goal"""\n        self.goal_pose = msg.pose\n        self.get_logger().info(f\'New goal received: {msg.pose.position}\')\n\n    def odom_callback(self, msg):\n        """Update current pose"""\n        self.current_pose = msg.pose.pose\n\n    def scan_callback(self, msg):\n        """Process laser scan for obstacle detection"""\n        # Use Isaac ROS accelerated obstacle detection\n        ranges = np.array(msg.ranges)\n        # Filter out invalid ranges\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        # Check for obstacles in front\n        front_ranges = valid_ranges[len(valid_ranges)//2-30:len(valid_ranges)//2+30]\n        if len(front_ranges) > 0 and np.min(front_ranges) < 0.5:\n            self.get_logger().warn(\'Obstacle detected in front!\')\n\n    def navigation_loop(self):\n        """Main navigation loop with Isaac ROS acceleration"""\n        if self.current_pose and self.goal_pose:\n            # Calculate desired velocity using Isaac ROS accelerated planners\n            cmd_vel = self.calculate_velocity_to_goal()\n            self.cmd_vel_pub.publish(cmd_vel)\n\n    def calculate_velocity_to_goal(self):\n        """Calculate velocity to reach goal (simplified)"""\n        cmd_vel = Twist()\n\n        # Simple proportional controller\n        if self.current_pose and self.goal_pose:\n            dx = self.goal_pose.position.x - self.current_pose.position.x\n            dy = self.goal_pose.position.y - self.current_pose.position.y\n\n            distance = np.sqrt(dx**2 + dy**2)\n\n            if distance > 0.1:  # If not at goal\n                cmd_vel.linear.x = min(0.5, distance * 0.5)  # Move toward goal\n                cmd_vel.angular.z = np.arctan2(dy, dx) - self.current_pose.orientation.z  # Turn toward goal\n            else:\n                cmd_vel.linear.x = 0.0\n                cmd_vel.angular.z = 0.0\n\n        return cmd_vel\n\ndef main(args=None):\n    rclpy.init(args=args)\n    nav_node = IsaacNavigationNode()\n\n    try:\n        rclpy.spin(nav_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        nav_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"best-practices-with-isaac-ros",children:"Best Practices with Isaac ROS"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hardware Requirements"}),": Ensure NVIDIA GPU hardware compatibility"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance Optimization"}),": Use appropriate data types and buffer sizes"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Model Deployment"}),": Optimize deep learning models for target hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Integration"}),": Follow ROS 2 conventions while leveraging Isaac capabilities"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Testing"}),": Validate performance improvements on target hardware"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS brings GPU acceleration and AI capabilities to the ROS 2 ecosystem, enabling robots to perform complex perception and navigation tasks with improved performance. By leveraging Isaac ROS GEMs, developers can accelerate their robotics applications."}),"\n",(0,a.jsx)(t.A,{title:"Isaac ROS Architecture",description:"Shows the components and GPU acceleration in Isaac ROS framework"})]})}function g(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}}}]);