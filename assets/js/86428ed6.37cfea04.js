"use strict";(globalThis.webpackChunkai_robotics_textbook=globalThis.webpackChunkai_robotics_textbook||[]).push([[768],{5408:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>_,frontMatter:()=>r,metadata:()=>d,toc:()=>m});var a=t(4848),o=t(8453),s=t(1226),i=t(5783);const r={sidebar_position:4,title:"Simulation and Deployment"},l="Simulation and Deployment",d={id:"module-3-nvidia-isaac/topic-3",title:"Simulation and Deployment",description:"This module covers the simulation and deployment aspects of NVIDIA Isaac, including Isaac Sim for advanced simulation and deployment strategies for Isaac-powered robotic systems.",source:"@site/docs/module-3-nvidia-isaac/topic-3.mdx",sourceDirName:"module-3-nvidia-isaac",slug:"/module-3-nvidia-isaac/topic-3",permalink:"/hackthon/docs/module-3-nvidia-isaac/topic-3",draft:!1,unlisted:!1,editUrl:"https://github.com/nehaltariq357/hackthon/tree/master/docs/module-3-nvidia-isaac/topic-3.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"Simulation and Deployment"},sidebar:"textbookSidebar",previous:{title:"AI Tools and Acceleration",permalink:"/hackthon/docs/module-3-nvidia-isaac/topic-2"},next:{title:"Module 4: Vision-Language-Action (VLA)",permalink:"/hackthon/docs/module-4-vla/"}},c={},m=[{value:"Isaac Sim Advanced Features",id:"isaac-sim-advanced-features",level:2},{value:"Deployment Strategies",id:"deployment-strategies",level:2},{value:"Containerized Deployment with Docker",id:"containerized-deployment-with-docker",level:2},{value:"Best Practices for Isaac Deployment",id:"best-practices-for-isaac-deployment",level:2},{value:"Summary",id:"summary",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.A,{}),"\n",(0,a.jsx)(n.h1,{id:"simulation-and-deployment",children:"Simulation and Deployment"}),"\n",(0,a.jsx)(n.p,{children:"This module covers the simulation and deployment aspects of NVIDIA Isaac, including Isaac Sim for advanced simulation and deployment strategies for Isaac-powered robotic systems."}),"\n",(0,a.jsx)(n.h2,{id:"isaac-sim-advanced-features",children:"Isaac Sim Advanced Features"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides advanced simulation capabilities for robotics development:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="isaac_sim_advanced_robot.py"',children:'import omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.sensor import Camera, LidarRtx\nimport numpy as np\n\nclass AdvancedIsaacSimRobot:\n    def __init__(self):\n        self.world = World(stage_units_in_meters=1.0)\n        self.robot = None\n        self.camera = None\n        self.lidar = None\n\n    def setup_robot_with_sensors(self):\n        """Setup robot with multiple sensors in Isaac Sim"""\n        # Get assets root path\n        assets_root_path = get_assets_root_path()\n        if assets_root_path is None:\n            carb.log_error("Could not find Isaac Sim assets folder")\n            return False\n\n        # Add robot to stage\n        jetbot_asset_path = assets_root_path + "/Isaac/Robots/Jetbot/jetbot.usd"\n        add_reference_to_stage(usd_path=jetbot_asset_path, prim_path="/World/Robot")\n\n        # Create robot instance\n        self.robot = self.world.scene.add(\n            Robot(\n                prim_path="/World/Robot",\n                name="my_jetbot",\n                position=np.array([0, 0, 0.2]),\n                orientation=np.array([1, 0, 0, 0])\n            )\n        )\n\n        # Add RGB camera\n        self.camera = self.world.scene.add(\n            Camera(\n                prim_path="/World/Robot/chassis/Camera",\n                name="rgb_camera",\n                position=np.array([0.2, 0, 0.1]),\n                frequency=30\n            )\n        )\n\n        # Add LiDAR sensor\n        self.lidar = self.world.scene.add(\n            LidarRtx(\n                prim_path="/World/Robot/chassis/Lidar",\n                name="velodyne_lidar",\n                translation=np.array([0.15, 0, 0.15]),\n                orientation=np.array([0, 0, 0, 1]),\n                config="Velodyne_VLP-16",\n                rotation_frequency=10,\n                samples_per_scan=1000\n            )\n        )\n\n        return True\n\n    def setup_complex_environment(self):\n        """Setup a complex simulation environment"""\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n\n        # Add various objects for testing\n        self.add_test_objects()\n\n        # Setup lighting\n        self.setup_environment_lighting()\n\n    def add_test_objects(self):\n        """Add various test objects to the environment"""\n        # Add cubes of different sizes and materials\n        for i in range(5):\n            cube = self.world.scene.add(\n                cuboid.Cuboid(\n                    prim_path=f"/World/Cube_{i}",\n                    name=f"cube_{i}",\n                    position=np.array([2 + i, 0, 0.5]),\n                    size=0.2,\n                    color=np.array([0.5, 0.5, 0.5])\n                )\n            )\n\n        # Add a table\n        table = self.world.scene.add(\n            cuboid.Cuboid(\n                prim_path="/World/Table",\n                name="table",\n                position=np.array([5, 0, 0.4]),\n                size=np.array([1.0, 0.8, 0.8]),\n                color=np.array([0.8, 0.6, 0.2])\n            )\n        )\n\n    def setup_environment_lighting(self):\n        """Setup realistic lighting for the environment"""\n        # Add dome light\n        dome_light = omni.lighting.lightdome domeLightAPI = PhysxSchema.PhysxDomeLightAPI.Apply(dome_light.prim)\n        dome_lightAPI.CreateIntensityAttr(500)\n\n        # Add directional light\n        directional_light = omni.lighting.core.add_directional_light(\n            prim_path="/World/DirectionalLight",\n            intensity=3000,\n            color=np.array([1, 1, 1])\n        )\n\n    def run_simulation_with_data_collection(self):\n        """Run simulation with data collection"""\n        # Reset the world\n        self.world.reset()\n\n        # Data collection variables\n        collected_data = {\n            \'images\': [],\n            \'lidar_data\': [],\n            \'robot_states\': [],\n            \'actions\': []\n        }\n\n        for step in range(1000):  # Run for 1000 steps\n            # Step the world\n            self.world.step(render=True)\n\n            # Collect sensor data\n            if step % 10 == 0:  # Collect data every 10 steps\n                image_data = self.camera.get_rgb()\n                lidar_data = self.lidar.get_linear_depth_data()\n\n                robot_position, robot_orientation = self.robot.get_world_pose()\n                robot_linear_vel, robot_angular_vel = self.robot.get_linear_velocity(), self.robot.get_angular_velocity()\n\n                collected_data[\'images\'].append(image_data)\n                collected_data[\'lidar_data\'].append(lidar_data)\n                collected_data[\'robot_states\'].append({\n                    \'position\': robot_position,\n                    \'orientation\': robot_orientation,\n                    \'linear_vel\': robot_linear_vel,\n                    \'angular_vel\': robot_angular_vel\n                })\n\n        return collected_data\n\n# ROS 2 node that interfaces with Isaac Sim\nclass IsaacSimInterfaceNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_sim_interface_node\')\n\n        # Publishers for simulation data\n        self.image_pub = self.create_publisher(CompressedImage, \'sim/camera/image_raw/compressed\', 10)\n        self.lidar_pub = self.create_publisher(LaserScan, \'sim/lidar/scan\', 10)\n        self.odom_pub = self.create_publisher(Odometry, \'sim/odom\', 10)\n\n        # Subscribers for commands\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, \'sim/cmd_vel\', self.cmd_vel_callback, 10)\n\n        # Timer for simulation loop\n        self.sim_timer = self.create_timer(0.033, self.simulation_callback)  # ~30 Hz\n\n        # Initialize Isaac Sim\n        self.sim_robot = AdvancedIsaacSimRobot()\n        if self.sim_robot.setup_robot_with_sensors():\n            self.sim_robot.setup_complex_environment()\n            self.get_logger().info(\'Isaac Sim environment initialized successfully\')\n        else:\n            self.get_logger().error(\'Failed to initialize Isaac Sim environment\')\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands from ROS"""\n        # Apply velocity commands to simulated robot\n        # This would interface with the Isaac Sim robot\n        linear_vel = [msg.linear.x, msg.linear.y, msg.linear.z]\n        angular_vel = [msg.angular.x, msg.angular.y, msg.angular.z]\n\n        # Apply to simulated robot (implementation depends on robot type)\n        # self.sim_robot.apply_velocity_command(linear_vel, angular_vel)\n\n    def simulation_callback(self):\n        """Main simulation callback"""\n        # Step the simulation\n        self.sim_robot.world.step(render=True)\n\n        # Publish sensor data\n        self.publish_sensor_data()\n\n    def publish_sensor_data(self):\n        """Publish sensor data as ROS messages"""\n        # Publish camera image\n        try:\n            image_data = self.sim_robot.camera.get_rgb()\n            if image_data is not None:\n                img_msg = self.bridge.cv2_to_compressed_imgmsg(image_data)\n                img_msg.header.stamp = self.get_clock().now().to_msg()\n                img_msg.header.frame_id = \'camera_rgb_optical_frame\'\n                self.image_pub.publish(img_msg)\n        except Exception as e:\n            self.get_logger().warn(f\'Error publishing camera data: {e}\')\n\n        # Publish LiDAR data\n        try:\n            lidar_data = self.sim_robot.lidar.get_linear_depth_data()\n            if lidar_data is not None:\n                scan_msg = LaserScan()\n                scan_msg.header.stamp = self.get_clock().now().to_msg()\n                scan_msg.header.frame_id = \'lidar_frame\'\n                scan_msg.angle_min = -np.pi\n                scan_msg.angle_max = np.pi\n                scan_msg.angle_increment = 0.01\n                scan_msg.time_increment = 0.0\n                scan_msg.scan_time = 0.1\n                scan_msg.range_min = 0.1\n                scan_msg.range_max = 100.0\n                scan_msg.ranges = lidar_data.flatten().tolist()\n                self.lidar_pub.publish(scan_msg)\n        except Exception as e:\n            self.get_logger().warn(f\'Error publishing lidar data: {e}\')\n\ndef main(args=None):\n    # Initialize Isaac Sim\n    from omni.isaac.kit import SimulationApp\n    simulation_app = SimulationApp({"headless": False})\n\n    rclpy.init(args=args)\n    sim_node = IsaacSimInterfaceNode()\n\n    try:\n        # Run ROS and Isaac Sim together\n        while simulation_app.is_running() and rclpy.ok():\n            rclpy.spin_once(sim_node, timeout_sec=0.01)\n            # Step Isaac Sim\n            sim_node.sim_robot.world.step(render=True)\n\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sim_node.destroy_node()\n        rclpy.shutdown()\n        simulation_app.close()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"deployment-strategies",children:"Deployment Strategies"}),"\n",(0,a.jsx)(n.p,{children:"Deploying Isaac-powered robots requires careful consideration of hardware and software requirements:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="isaac_deployment_manager.py"',children:'import subprocess\nimport json\nimport os\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\n\n@dataclass\nclass HardwareConfig:\n    platform: str  # "jetson", "x86_64", "other"\n    gpu_support: bool\n    memory_gb: int\n    storage_gb: int\n\n@dataclass\nclass DeploymentConfig:\n    hardware: HardwareConfig\n    models: List[str]\n    packages: List[str]\n    network_config: Dict[str, str]\n\nclass IsaacDeploymentManager:\n    def __init__(self, config_path: str):\n        self.config = self.load_config(config_path)\n        self.deployment_path = Path("/opt/isaac_robot")\n\n    def load_config(self, config_path: str) -> DeploymentConfig:\n        """Load deployment configuration from file"""\n        with open(config_path, \'r\') as f:\n            config_data = json.load(f)\n\n        return DeploymentConfig(\n            hardware=HardwareConfig(**config_data[\'hardware\']),\n            models=config_data[\'models\'],\n            packages=config_data[\'packages\'],\n            network_config=config_data[\'network\']\n        )\n\n    def validate_hardware_compatibility(self) -> bool:\n        """Validate that the target hardware is compatible"""\n        # Check platform compatibility\n        if self.config.hardware.platform not in ["jetson", "x86_64"]:\n            self.get_logger().error(f"Unsupported platform: {self.config.hardware.platform}")\n            return False\n\n        # Check memory requirements\n        if self.config.hardware.memory_gb < 4:\n            self.get_logger().error("Insufficient memory for Isaac deployment")\n            return False\n\n        # Check for NVIDIA GPU if required\n        if self.config.hardware.gpu_support:\n            try:\n                result = subprocess.run([\'nvidia-smi\'], capture_output=True, text=True)\n                if result.returncode != 0:\n                    self.get_logger().error("NVIDIA GPU not detected")\n                    return False\n            except FileNotFoundError:\n                self.get_logger().error("nvidia-smi not found - NVIDIA drivers may not be installed")\n                return False\n\n        return True\n\n    def install_dependencies(self):\n        """Install system dependencies for Isaac deployment"""\n        commands = []\n\n        # Install base dependencies\n        if self.config.hardware.platform == "jetson":\n            commands.extend([\n                "apt-get update",\n                "apt-get install -y nvidia-jetpack",\n                "apt-get install -y ros-humble-isaac-ros-*"\n            ])\n        elif self.config.hardware.platform == "x86_64":\n            commands.extend([\n                "apt-get update",\n                "apt-get install -y nvidia-driver-470",\n                "apt-get install -y ros-humble-isaac-ros-*"\n            ])\n\n        # Install Python dependencies\n        commands.append("pip3 install -r requirements.txt")\n\n        for cmd in commands:\n            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n            if result.returncode != 0:\n                raise Exception(f"Command failed: {cmd}\\n{result.stderr}")\n\n    def deploy_models(self):\n        """Deploy AI models to target hardware"""\n        for model_name in self.config.models:\n            model_path = f"/models/{model_name}"\n            dest_path = self.deployment_path / "models" / model_name\n\n            # Optimize model with TensorRT if possible\n            if self.is_tensorrt_available():\n                self.optimize_model_with_tensorrt(model_path, dest_path)\n            else:\n                # Copy model as-is\n                subprocess.run(["cp", "-r", model_path, dest_path])\n\n    def optimize_model_with_tensorrt(self, model_path: str, dest_path: Path):\n        """Optimize model with TensorRT for deployment"""\n        # Convert ONNX to TensorRT engine\n        engine_path = dest_path.with_suffix(\'.plan\')\n        cmd = [\n            "trtexec",\n            f"--onnx={model_path}",\n            f"--saveEngine={engine_path}",\n            "--fp16",  # Use FP16 precision for better performance\n            "--buildOnly"\n        ]\n\n        result = subprocess.run(cmd, capture_output=True, text=True)\n        if result.returncode != 0:\n            raise Exception(f"TensorRT optimization failed: {result.stderr}")\n\n    def setup_networking(self):\n        """Setup networking configuration for the robot"""\n        # Configure ROS domain ID\n        domain_id = self.config.network_config.get(\'ros_domain_id\', 0)\n        os.environ[\'ROS_DOMAIN_ID\'] = str(domain_id)\n\n        # Configure network interfaces if specified\n        if \'network_interfaces\' in self.config.network_config:\n            for interface, config in self.config.network_config[\'network_interfaces\'].items():\n                self.configure_network_interface(interface, config)\n\n    def configure_network_interface(self, interface: str, config: Dict):\n        """Configure a specific network interface"""\n        # Set static IP if specified\n        if \'ip_address\' in config:\n            cmd = f"ip addr add {config[\'ip_address\']}/{config[\'subnet_mask\']} dev {interface}"\n            subprocess.run(cmd, shell=True)\n\n        # Set up ROS communication\n        if config.get(\'ros_enabled\', True):\n            # Configure DDS settings\n            os.environ[\'RMW_IMPLEMENTATION\'] = \'rmw_cyclonedx_cpp\'\n            os.environ[\'CYCLONEDX_PROFILE\'] = \'robot\'\n\n    def start_robot_system(self):\n        """Start the deployed robot system"""\n        # Source ROS environment\n        ros_setup = "source /opt/ros/humble/setup.bash"\n\n        # Launch main robot system\n        launch_cmd = f"{ros_setup} && ros2 launch my_robot_bringup robot.launch.py"\n        process = subprocess.Popen(launch_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        return process\n\n    def monitor_deployment(self):\n        """Monitor the deployed system"""\n        import psutil\n        import GPUtil\n\n        # Monitor system resources\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory_percent = psutil.virtual_memory().percent\n\n        # Monitor GPU if available\n        gpu_percent = 0\n        gpu_memory_percent = 0\n        if self.config.hardware.gpu_support:\n            gpus = GPUtil.getGPUs()\n            if gpus:\n                gpu = gpus[0]  # Use first GPU\n                gpu_percent = gpu.load * 100\n                gpu_memory_percent = gpu.memoryUtil * 100\n\n        # Log resource usage\n        self.get_logger().info(\n            f"Resource usage - CPU: {cpu_percent}%, "\n            f"Memory: {memory_percent}%, "\n            f"GPU: {gpu_percent}%, "\n            f"GPU Memory: {gpu_memory_percent}%"\n        )\n\ndef main():\n    """Main deployment script"""\n    deployment_manager = IsaacDeploymentManager(\'deployment_config.json\')\n\n    try:\n        # Validate hardware compatibility\n        if not deployment_manager.validate_hardware_compatibility():\n            print("Hardware validation failed")\n            return 1\n\n        # Install dependencies\n        print("Installing dependencies...")\n        deployment_manager.install_dependencies()\n\n        # Deploy models\n        print("Deploying models...")\n        deployment_manager.deploy_models()\n\n        # Setup networking\n        print("Setting up networking...")\n        deployment_manager.setup_networking()\n\n        # Start robot system\n        print("Starting robot system...")\n        robot_process = deployment_manager.start_robot_system()\n\n        # Monitor deployment\n        print("Monitoring deployment...")\n        while True:\n            deployment_manager.monitor_deployment()\n            import time\n            time.sleep(5)\n\n    except Exception as e:\n        print(f"Deployment failed: {e}")\n        return 1\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"containerized-deployment-with-docker",children:"Containerized Deployment with Docker"}),"\n",(0,a.jsx)(n.p,{children:"For consistent deployment across different hardware platforms:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-dockerfile",metastring:'title="Dockerfile.isaac"',children:'# Use NVIDIA CUDA base image\nFROM nvidia/cuda:11.8-devel-ubuntu22.04\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    python3 \\\n    python3-pip \\\n    python3-dev \\\n    build-essential \\\n    git \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install ROS 2 Humble\nRUN curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\nRUN echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu jammy main" | tee /etc/apt/sources.list.d/ros2.list\nRUN apt-get update && apt-get install -y \\\n    ros-humble-ros-base \\\n    ros-humble-isaac-ros-common \\\n    ros-humble-isaac-ros-gems \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip3 install -r requirements.txt\n\n# Set environment variables\nENV ROS_DISTRO=humble\nENV NVIDIA_VISIBLE_DEVICES=all\nENV NVIDIA_DRIVER_CAPABILITIES=compute,utility\nENV NVIDIA_REQUIRE_CUDA="cuda>=11.8"\n\n# Copy application code\nCOPY . /app\nWORKDIR /app\n\n# Source ROS environment\nRUN echo "source /opt/ros/humble/setup.bash" >> ~/.bashrc\n\n# Default command\nCMD ["bash"]\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",metastring:'title="deploy_docker.sh"',children:'#!/bin/bash\n\n# Build the Isaac ROS Docker image\ndocker build -t isaac-ros-robot -f Dockerfile.isaac .\n\n# Run the container with GPU support\ndocker run -it --gpus all \\\n    --env ROS_DOMAIN_ID=42 \\\n    --network host \\\n    --name isaac-robot \\\n    isaac-ros-robot \\\n    bash -c "source /opt/ros/humble/setup.bash && python3 robot_main.py"\n'})}),"\n",(0,a.jsx)(n.h2,{id:"best-practices-for-isaac-deployment",children:"Best Practices for Isaac Deployment"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hardware Validation"}),": Always validate hardware compatibility before deployment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Model Optimization"}),": Use TensorRT to optimize models for target hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Resource Monitoring"}),": Monitor system resources during operation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Configuration Management"}),": Use configuration files for different deployment scenarios"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Rollback Strategy"}),": Implement rollback capabilities for failed deployments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Security"}),": Secure communication channels and implement proper access controls"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides powerful simulation capabilities for robotics development, while Isaac's deployment tools enable efficient transfer of trained models and systems to real hardware. By following best practices for simulation and deployment, developers can create robust robotic systems that perform well in real-world scenarios."}),"\n",(0,a.jsx)(s.A,{title:"Isaac Deployment Pipeline",description:"Shows the pipeline from simulation to deployment in Isaac ecosystem"})]})}function _(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}}}]);