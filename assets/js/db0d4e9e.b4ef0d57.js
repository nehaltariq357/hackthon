"use strict";(globalThis.webpackChunkai_robotics_textbook=globalThis.webpackChunkai_robotics_textbook||[]).push([[637],{1902:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>_,contentTitle:()=>l,default:()=>m,frontMatter:()=>r,metadata:()=>c,toc:()=>f});var a=t(4848),s=t(8453),o=t(1226),i=t(5783);const r={sidebar_position:3,title:"Autonomous Behavior Implementation"},l="Autonomous Behavior Implementation",c={id:"capstone-project/topic-2",title:"Autonomous Behavior Implementation",description:"This module focuses on implementing autonomous behaviors that integrate all components of the humanoid robot system. We'll create complex behaviors that demonstrate the full capability of the Vision-Language-Action framework in a humanoid context.",source:"@site/docs/capstone-project/topic-2.mdx",sourceDirName:"capstone-project",slug:"/capstone-project/topic-2",permalink:"/docs/capstone-project/topic-2",draft:!1,unlisted:!1,editUrl:"https://github.com/nehaltariq357/hackthon/tree/master/docs/capstone-project/topic-2.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Autonomous Behavior Implementation"},sidebar:"textbookSidebar",previous:{title:"Humanoid Robot Integration",permalink:"/docs/capstone-project/topic-1"}},_={},f=[{value:"Overview of Autonomous Behaviors",id:"overview-of-autonomous-behaviors",level:2},{value:"Complex Behavior Implementation",id:"complex-behavior-implementation",level:2},{value:"Learning and Adaptation System",id:"learning-and-adaptation-system",level:2},{value:"Social Interaction Behaviors",id:"social-interaction-behaviors",level:2},{value:"Integration and Testing",id:"integration-and-testing",level:2},{value:"Best Practices for Autonomous Behavior",id:"best-practices-for-autonomous-behavior",level:2},{value:"Summary",id:"summary",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.A,{}),"\n",(0,a.jsx)(n.h1,{id:"autonomous-behavior-implementation",children:"Autonomous Behavior Implementation"}),"\n",(0,a.jsx)(n.p,{children:"This module focuses on implementing autonomous behaviors that integrate all components of the humanoid robot system. We'll create complex behaviors that demonstrate the full capability of the Vision-Language-Action framework in a humanoid context."}),"\n",(0,a.jsx)(n.h2,{id:"overview-of-autonomous-behaviors",children:"Overview of Autonomous Behaviors"}),"\n",(0,a.jsx)(n.p,{children:"Autonomous behaviors for humanoid robots involve:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Behavior Trees"}),": Hierarchical task execution"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"State Machines"}),": Reactive behavior control"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Learning Systems"}),": Adaptive behavior improvement"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Social Interaction"}),": Human-robot interaction protocols"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"complex-behavior-implementation",children:"Complex Behavior Implementation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="complex_behavior_manager.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nfrom geometry_msgs.msg import Pose, Twist\nfrom sensor_msgs.msg import JointState, Image, LaserScan\nfrom action_msgs.msg import GoalStatus\nfrom rclpy.action import ActionClient\nfrom threading import Lock\nimport json\nimport time\nfrom enum import Enum\nfrom typing import Dict, Any, List, Optional\n\nclass BehaviorState(Enum):\n    IDLE = 1\n    LISTENING = 2\n    UNDERSTANDING = 3\n    PLANNING = 4\n    EXECUTING = 5\n    MONITORING = 6\n    RECOVERING = 7\n    COMPLETED = 8\n    FAILED = 9\n\nclass ComplexBehaviorManager(Node):\n    def __init__(self):\n        super().__init__('complex_behavior_manager')\n\n        # Publishers and subscribers\n        self.behavior_command_sub = self.create_subscription(\n            String, 'complex_behavior_command', self.behavior_command_callback, 10)\n        self.behavior_status_pub = self.create_publisher(\n            String, 'behavior_status', 10)\n        self.interrupt_sub = self.create_subscription(\n            Bool, 'behavior_interrupt', self.interrupt_callback, 10)\n\n        # Component interfaces\n        self.vision_sub = self.create_subscription(\n            Image, 'camera/image_raw', self.vision_callback, 10)\n        self.laser_sub = self.create_subscription(\n            LaserScan, 'scan', self.laser_callback, 10)\n        self.joint_state_sub = self.create_subscription(\n            JointState, 'joint_states', self.joint_state_callback, 10)\n\n        # Internal state\n        self.current_behavior = None\n        self.behavior_state = BehaviorState.IDLE\n        self.behavior_params = {}\n        self.interrupt_requested = False\n        self.vision_data = None\n        self.laser_data = None\n        self.joint_positions = {}\n\n        # Thread safety\n        self.state_lock = Lock()\n\n        # Timer for behavior execution\n        self.behavior_timer = self.create_timer(0.1, self.execute_behavior)\n\n    def behavior_command_callback(self, msg):\n        \"\"\"Handle complex behavior commands\"\"\"\n        try:\n            command_data = json.loads(msg.data)\n            behavior_type = command_data.get('behavior', 'unknown')\n            params = command_data.get('parameters', {})\n\n            self.get_logger().info(f'Received behavior command: {behavior_type}')\n\n            # Start the requested behavior\n            self.start_behavior(behavior_type, params)\n\n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON in behavior command: {msg.data}')\n        except Exception as e:\n            self.get_logger().error(f'Error processing behavior command: {e}')\n\n    def start_behavior(self, behavior_type: str, params: Dict[str, Any]):\n        \"\"\"Start executing a complex behavior\"\"\"\n        with self.state_lock:\n            self.current_behavior = behavior_type\n            self.behavior_params = params\n            self.behavior_state = BehaviorState.LISTENING\n            self.interrupt_requested = False\n\n        self.get_logger().info(f'Starting behavior: {behavior_type}')\n        self.publish_behavior_status(f'STARTED: {behavior_type}')\n\n    def interrupt_callback(self, msg):\n        \"\"\"Handle behavior interruption requests\"\"\"\n        if msg.data:\n            self.interrupt_requested = True\n            self.get_logger().info('Behavior interruption requested')\n            self.publish_behavior_status('INTERRUPTED')\n\n    def vision_callback(self, msg):\n        \"\"\"Update vision data\"\"\"\n        self.vision_data = msg\n\n    def laser_callback(self, msg):\n        \"\"\"Update laser data\"\"\"\n        self.laser_data = msg.ranges\n\n    def joint_state_callback(self, msg):\n        \"\"\"Update joint positions\"\"\"\n        for i, name in enumerate(msg.name):\n            self.joint_positions[name] = msg.position[i]\n\n    def execute_behavior(self):\n        \"\"\"Execute the current behavior based on state\"\"\"\n        if self.behavior_state == BehaviorState.IDLE:\n            return\n\n        if self.interrupt_requested:\n            self.behavior_state = BehaviorState.FAILED\n            self.publish_behavior_status('INTERRUPTED')\n            return\n\n        # Execute based on current state\n        if self.behavior_state == BehaviorState.LISTENING:\n            self.execute_listening_state()\n        elif self.behavior_state == BehaviorState.UNDERSTANDING:\n            self.execute_understanding_state()\n        elif self.behavior_state == BehaviorState.PLANNING:\n            self.execute_planning_state()\n        elif self.behavior_state == BehaviorState.EXECUTING:\n            self.execute_executing_state()\n        elif self.behavior_state == BehaviorState.MONITORING:\n            self.execute_monitoring_state()\n        elif self.behavior_state == BehaviorState.RECOVERING:\n            self.execute_recovering_state()\n\n    def execute_listening_state(self):\n        \"\"\"Execute listening state - waiting for input\"\"\"\n        # In a real system, this would wait for voice or gesture input\n        # For demo, transition to understanding after a short delay\n        self.behavior_state = BehaviorState.UNDERSTANDING\n        self.get_logger().info('Transitioned to understanding state')\n\n    def execute_understanding_state(self):\n        \"\"\"Execute understanding state - processing input\"\"\"\n        # Process the input to understand the request\n        if self.current_behavior:\n            self.get_logger().info(f'Understanding behavior request: {self.current_behavior}')\n            self.behavior_state = BehaviorState.PLANNING\n\n    def execute_planning_state(self):\n        \"\"\"Execute planning state - creating action plan\"\"\"\n        if self.current_behavior == 'guided_tour':\n            self.plan_guided_tour()\n        elif self.current_behavior == 'object_search':\n            self.plan_object_search()\n        elif self.current_behavior == 'social_interaction':\n            self.plan_social_interaction()\n        else:\n            self.get_logger().warn(f'Unknown behavior type: {self.current_behavior}')\n            self.behavior_state = BehaviorState.FAILED\n\n    def plan_guided_tour(self):\n        \"\"\"Plan a guided tour behavior\"\"\"\n        self.get_logger().info('Planning guided tour')\n        # Create a sequence of navigation and explanation steps\n        self.behavior_plan = [\n            {'action': 'navigate', 'params': {'location': 'entrance', 'description': 'Welcome to our facility!'}},\n            {'action': 'navigate', 'params': {'location': 'lobby', 'description': 'This is our main lobby area.'}},\n            {'action': 'navigate', 'params': {'location': 'lab', 'description': 'Here is where the research happens.'}},\n            {'action': 'navigate', 'params': {'location': 'exit', 'description': 'Thank you for the visit!'}}\n        ]\n        self.current_plan_step = 0\n        self.behavior_state = BehaviorState.EXECUTING\n\n    def plan_object_search(self):\n        \"\"\"Plan an object search behavior\"\"\"\n        self.get_logger().info('Planning object search')\n        target_object = self.behavior_params.get('object', 'unknown')\n\n        self.behavior_plan = [\n            {'action': 'search_area', 'params': {'object': target_object}},\n            {'action': 'approach_object', 'params': {'object': target_object}},\n            {'action': 'verify_object', 'params': {'object': target_object}},\n            {'action': 'report_result', 'params': {'object': target_object}}\n        ]\n        self.current_plan_step = 0\n        self.behavior_state = BehaviorState.EXECUTING\n\n    def plan_social_interaction(self):\n        \"\"\"Plan a social interaction behavior\"\"\"\n        self.get_logger().info('Planning social interaction')\n        interaction_type = self.behavior_params.get('type', 'greeting')\n\n        if interaction_type == 'greeting':\n            self.behavior_plan = [\n                {'action': 'detect_person', 'params': {}},\n                {'action': 'greet_person', 'params': {}},\n                {'action': 'wait_for_response', 'params': {}},\n                {'action': 'engage_conversation', 'params': {}}\n            ]\n        elif interaction_type == 'assistance':\n            self.behavior_plan = [\n                {'action': 'detect_person', 'params': {}},\n                {'action': 'offer_assistance', 'params': {}},\n                {'action': 'wait_for_request', 'params': {}},\n                {'action': 'provide_assistance', 'params': {}}\n            ]\n\n        self.current_plan_step = 0\n        self.behavior_state = BehaviorState.EXECUTING\n\n    def execute_executing_state(self):\n        \"\"\"Execute the current plan step\"\"\"\n        if not hasattr(self, 'behavior_plan') or self.current_plan_step >= len(self.behavior_plan):\n            # Plan completed\n            self.behavior_state = BehaviorState.MONITORING\n            return\n\n        current_step = self.behavior_plan[self.current_plan_step]\n        action = current_step['action']\n        params = current_step['params']\n\n        self.get_logger().info(f'Executing step {self.current_plan_step + 1}: {action}')\n\n        # Execute the action\n        success = self.execute_action(action, params)\n\n        if success:\n            self.current_plan_step += 1\n            if self.current_plan_step >= len(self.behavior_plan):\n                # All steps completed\n                self.behavior_state = BehaviorState.MONITORING\n        else:\n            # Action failed, try again or go to recovery\n            self.behavior_state = BehaviorState.RECOVERING\n\n    def execute_action(self, action: str, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute a specific action\"\"\"\n        if action == 'navigate':\n            return self.execute_navigation_action(params)\n        elif action == 'search_area':\n            return self.execute_search_action(params)\n        elif action == 'approach_object':\n            return self.execute_approach_action(params)\n        elif action == 'detect_person':\n            return self.execute_detect_person_action(params)\n        elif action == 'greet_person':\n            return self.execute_greet_action(params)\n        elif action == 'verify_object':\n            return self.execute_verify_action(params)\n        else:\n            self.get_logger().warn(f'Unknown action: {action}')\n            return False\n\n    def execute_navigation_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute navigation action\"\"\"\n        location = params.get('location', 'unknown')\n        description = params.get('description', '')\n\n        self.get_logger().info(f'Navigating to {location}: {description}')\n        # In real implementation, this would use navigation stack\n        # For demo, simulate completion after delay\n        time.sleep(0.5)  # Simulate navigation time\n        return True\n\n    def execute_search_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute search action\"\"\"\n        target_object = params.get('object', 'unknown')\n        self.get_logger().info(f'Searching for {target_object}')\n\n        # In real implementation, this would use perception system\n        # For demo, simulate search and return success\n        time.sleep(1.0)  # Simulate search time\n        return True\n\n    def execute_approach_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute approach action\"\"\"\n        target_object = params.get('object', 'unknown')\n        self.get_logger().info(f'Approaching {target_object}')\n\n        # In real implementation, navigate to object\n        time.sleep(0.5)  # Simulate approach time\n        return True\n\n    def execute_detect_person_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute person detection action\"\"\"\n        self.get_logger().info('Detecting person')\n\n        # In real implementation, use perception system\n        time.sleep(0.3)  # Simulate detection time\n        return True\n\n    def execute_greet_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute greeting action\"\"\"\n        self.get_logger().info('Greeting person')\n        # In real implementation, use speech system\n        return True\n\n    def execute_verify_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute object verification action\"\"\"\n        target_object = params.get('object', 'unknown')\n        self.get_logger().info(f'Verifying {target_object}')\n\n        # In real implementation, use perception to verify\n        time.sleep(0.2)  # Simulate verification time\n        return True\n\n    def execute_monitoring_state(self):\n        \"\"\"Monitor behavior completion\"\"\"\n        self.behavior_state = BehaviorState.COMPLETED\n        self.publish_behavior_status(f'COMPLETED: {self.current_behavior}')\n        self.get_logger().info(f'Behavior completed: {self.current_behavior}')\n\n        # Reset for next behavior\n        with self.state_lock:\n            self.current_behavior = None\n            self.behavior_state = BehaviorState.IDLE\n\n    def execute_recovering_state(self):\n        \"\"\"Execute recovery from failure\"\"\"\n        self.get_logger().info(f'Attempting to recover from failure in {self.current_behavior}')\n\n        # In real implementation, try alternative approaches\n        self.behavior_state = BehaviorState.FAILED\n        self.publish_behavior_status(f'FAILED: {self.current_behavior}')\n\n        # Reset for next behavior\n        with self.state_lock:\n            self.current_behavior = None\n            self.behavior_state = BehaviorState.IDLE\n\n    def publish_behavior_status(self, status: str):\n        \"\"\"Publish behavior status\"\"\"\n        status_msg = String()\n        status_msg.data = status\n        self.behavior_status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    behavior_manager = ComplexBehaviorManager()\n\n    try:\n        rclpy.spin(behavior_manager)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        behavior_manager.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-and-adaptation-system",children:"Learning and Adaptation System"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="adaptive_behavior_system.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose\nfrom sensor_msgs.msg import JointState\nfrom builtin_interfaces.msg import Time\nimport json\nimport numpy as np\nfrom typing import Dict, List, Any, Optional\nimport pickle\nimport os\n\nclass AdaptiveBehaviorSystem(Node):\n    def __init__(self):\n        super().__init__('adaptive_behavior_system')\n\n        # Publishers and subscribers\n        self.experience_sub = self.create_subscription(\n            String, 'behavior_experience', self.experience_callback, 10)\n        self.adaptation_command_sub = self.create_subscription(\n            String, 'adaptation_command', self.adaptation_command_callback, 10)\n\n        # Internal state\n        self.experience_buffer = []\n        self.behavior_models = {}\n        self.performance_history = {}\n        self.adaptation_threshold = 0.7  # Performance threshold for adaptation\n\n        # Load any existing models\n        self.load_models()\n\n        # Timer for continuous adaptation\n        self.adaptation_timer = self.create_timer(5.0, self.periodic_adaptation)\n\n    def experience_callback(self, msg):\n        \"\"\"Handle experience data from behaviors\"\"\"\n        try:\n            experience_data = json.loads(msg.data)\n            behavior_name = experience_data.get('behavior', 'unknown')\n            outcome = experience_data.get('outcome', 'unknown')\n            context = experience_data.get('context', {})\n            performance = experience_data.get('performance', 0.0)\n\n            # Store experience\n            experience = {\n                'behavior': behavior_name,\n                'outcome': outcome,\n                'context': context,\n                'performance': performance,\n                'timestamp': self.get_clock().now().nanoseconds / 1e9\n            }\n\n            self.experience_buffer.append(experience)\n\n            # Keep only recent experiences (last 100)\n            if len(self.experience_buffer) > 100:\n                self.experience_buffer = self.experience_buffer[-100:]\n\n            self.get_logger().info(f'Recorded experience for {behavior_name}, performance: {performance:.2f}')\n\n            # Update performance history\n            if behavior_name not in self.performance_history:\n                self.performance_history[behavior_name] = []\n            self.performance_history[behavior_name].append(performance)\n\n            # Check if adaptation is needed\n            self.check_adaptation_needed(behavior_name)\n\n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON in experience: {msg.data}')\n        except Exception as e:\n            self.get_logger().error(f'Error processing experience: {e}')\n\n    def adaptation_command_callback(self, msg):\n        \"\"\"Handle explicit adaptation commands\"\"\"\n        try:\n            command_data = json.loads(msg.data)\n            command = command_data.get('command', 'unknown')\n            target_behavior = command_data.get('behavior', 'all')\n\n            if command == 'adapt':\n                self.adapt_behavior(target_behavior)\n            elif command == 'reset':\n                self.reset_behavior(target_behavior)\n            elif command == 'save':\n                self.save_models()\n            elif command == 'load':\n                self.load_models()\n\n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON in adaptation command: {msg.data}')\n\n    def check_adaptation_needed(self, behavior_name: str):\n        \"\"\"Check if adaptation is needed for a behavior\"\"\"\n        if behavior_name in self.performance_history:\n            recent_performance = self.performance_history[behavior_name][-5:]  # Last 5 performances\n            if len(recent_performance) >= 5:\n                avg_performance = sum(recent_performance) / len(recent_performance)\n\n                if avg_performance < self.adaptation_threshold:\n                    self.get_logger().warn(f'Performance degradation detected for {behavior_name}, adapting...')\n                    self.adapt_behavior(behavior_name)\n\n    def adapt_behavior(self, behavior_name: str):\n        \"\"\"Adapt a specific behavior based on experience\"\"\"\n        if behavior_name == 'all':\n            # Adapt all behaviors\n            for name in self.performance_history.keys():\n                self._adapt_single_behavior(name)\n        else:\n            self._adapt_single_behavior(behavior_name)\n\n    def _adapt_single_behavior(self, behavior_name: str):\n        \"\"\"Adapt a single behavior\"\"\"\n        self.get_logger().info(f'Adapting behavior: {behavior_name}')\n\n        # Get relevant experiences\n        relevant_experiences = [\n            exp for exp in self.experience_buffer\n            if exp['behavior'] == behavior_name\n        ]\n\n        if len(relevant_experiences) < 3:\n            self.get_logger().info(f'Not enough experiences to adapt {behavior_name}')\n            return\n\n        # Analyze experiences to identify patterns\n        successful_experiences = [exp for exp in relevant_experiences if exp['outcome'] == 'success']\n        failed_experiences = [exp for exp in relevant_experiences if exp['outcome'] == 'failure']\n\n        # Identify conditions that lead to success/failure\n        success_contexts = [exp['context'] for exp in successful_experiences]\n        failure_contexts = [exp['context'] for exp in failed_experiences]\n\n        # Create adaptation strategy\n        adaptation_strategy = self.create_adaptation_strategy(\n            success_contexts, failure_contexts, behavior_name\n        )\n\n        # Apply adaptation\n        self.apply_adaptation(adaptation_strategy, behavior_name)\n\n        self.get_logger().info(f'Adaptation completed for {behavior_name}')\n\n    def create_adaptation_strategy(self, success_contexts: List[Dict],\n                                 failure_contexts: List[Dict], behavior_name: str) -> Dict[str, Any]:\n        \"\"\"Create an adaptation strategy based on experience analysis\"\"\"\n        strategy = {\n            'behavior': behavior_name,\n            'modifications': [],\n            'new_parameters': {}\n        }\n\n        # Analyze context differences between success and failure\n        if success_contexts and failure_contexts:\n            # Example: If lighting condition affects performance\n            success_lighting = [ctx.get('lighting', 0.5) for ctx in success_contexts if 'lighting' in ctx]\n            failure_lighting = [ctx.get('lighting', 0.5) for ctx in failure_contexts if 'lighting' in ctx]\n\n            if success_lighting and failure_lighting:\n                avg_success_lighting = sum(success_lighting) / len(success_lighting)\n                avg_failure_lighting = sum(failure_lighting) / len(failure_lighting)\n\n                if abs(avg_success_lighting - avg_failure_lighting) > 0.2:\n                    strategy['new_parameters']['lighting_sensitivity'] = avg_success_lighting\n\n            # Example: If object size affects performance\n            success_object_sizes = [ctx.get('object_size', 0.1) for ctx in success_contexts if 'object_size' in ctx]\n            failure_object_sizes = [ctx.get('object_size', 0.1) for ctx in failure_contexts if 'object_size' in ctx]\n\n            if success_object_sizes and failure_object_sizes:\n                avg_success_size = sum(success_object_sizes) / len(success_object_sizes)\n                avg_failure_size = sum(failure_object_sizes) / len(failure_object_sizes)\n\n                if abs(avg_success_size - avg_failure_size) > 0.05:\n                    strategy['new_parameters']['size_threshold'] = (avg_success_size + avg_failure_size) / 2\n\n        return strategy\n\n    def apply_adaptation(self, strategy: Dict[str, Any], behavior_name: str):\n        \"\"\"Apply the adaptation strategy to a behavior\"\"\"\n        # In a real system, this would update behavior parameters or models\n        # For this example, we'll just store the strategy\n        self.behavior_models[behavior_name] = strategy\n\n        # Publish adaptation notification\n        adaptation_msg = String()\n        adaptation_msg.data = json.dumps({\n            'behavior': behavior_name,\n            'adaptation_applied': True,\n            'parameters': strategy.get('new_parameters', {})\n        })\n\n        adaptation_pub = self.create_publisher(String, f'{behavior_name}_adaptation', 10)\n        adaptation_pub.publish(adaptation_msg)\n\n    def reset_behavior(self, behavior_name: str):\n        \"\"\"Reset a behavior to default parameters\"\"\"\n        if behavior_name in self.behavior_models:\n            del self.behavior_models[behavior_name]\n            self.get_logger().info(f'Reset behavior: {behavior_name}')\n\n    def periodic_adaptation(self):\n        \"\"\"Periodically check for adaptation opportunities\"\"\"\n        for behavior_name in self.performance_history.keys():\n            self.check_adaptation_needed(behavior_name)\n\n    def save_models(self):\n        \"\"\"Save learned models to file\"\"\"\n        models_data = {\n            'behavior_models': self.behavior_models,\n            'performance_history': self.performance_history,\n            'experience_buffer': self.experience_buffer\n        }\n\n        try:\n            with open('/tmp/humanoid_models.pkl', 'wb') as f:\n                pickle.dump(models_data, f)\n            self.get_logger().info('Models saved successfully')\n        except Exception as e:\n            self.get_logger().error(f'Error saving models: {e}')\n\n    def load_models(self):\n        \"\"\"Load learned models from file\"\"\"\n        if os.path.exists('/tmp/humanoid_models.pkl'):\n            try:\n                with open('/tmp/humanoid_models.pkl', 'rb') as f:\n                    models_data = pickle.load(f)\n\n                self.behavior_models = models_data.get('behavior_models', {})\n                self.performance_history = models_data.get('performance_history', {})\n                self.experience_buffer = models_data.get('experience_buffer', [])\n\n                self.get_logger().info('Models loaded successfully')\n            except Exception as e:\n                self.get_logger().error(f'Error loading models: {e}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    adaptation_system = AdaptiveBehaviorSystem()\n\n    try:\n        rclpy.spin(adaptation_system)\n    except KeyboardInterrupt:\n        # Save models before shutting down\n        adaptation_system.save_models()\n        pass\n    finally:\n        adaptation_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"social-interaction-behaviors",children:"Social Interaction Behaviors"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="social_interaction_behaviors.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nfrom geometry_msgs.msg import Pose, Twist\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport json\nimport math\nfrom typing import Dict, Any, List, Optional\n\nclass SocialInteractionBehaviors(Node):\n    def __init__(self):\n        super().__init__('social_interaction_behaviors')\n\n        # Initialize CV Bridge\n        self.bridge = CvBridge()\n\n        # Publishers and subscribers\n        self.social_command_sub = self.create_subscription(\n            String, 'social_behavior_command', self.social_command_callback, 10)\n        self.face_detection_sub = self.create_subscription(\n            String, 'face_detection_results', self.face_detection_callback, 10)\n        self.speech_recognition_sub = self.create_subscription(\n            String, 'speech_recognition', self.speech_recognition_callback, 10)\n        self.social_status_pub = self.create_publisher(\n            String, 'social_status', 10)\n        self.cmd_vel_pub = self.create_publisher(Twist, 'cmd_vel', 10)\n        self.head_control_pub = self.create_publisher(\n            String, 'head_control', 10)  # For head/eye movements\n\n        # Internal state\n        self.attended_person = None\n        self.conversation_history = []\n        self.social_engagement_active = False\n        self.face_tracking_active = False\n\n        # Social behavior parameters\n        self.social_params = {\n            'personal_space': 1.0,  # meters\n            'greeting_distance': 1.5,  # meters\n            'attention_span': 10.0,  # seconds\n            'gaze_timeout': 3.0  # seconds\n        }\n\n        # Timer for social behavior execution\n        self.social_timer = self.create_timer(0.1, self.social_behavior_loop)\n\n    def social_command_callback(self, msg):\n        \"\"\"Handle social behavior commands\"\"\"\n        try:\n            command_data = json.loads(msg.data)\n            behavior = command_data.get('behavior', 'unknown')\n            params = command_data.get('parameters', {})\n\n            self.get_logger().info(f'Received social behavior: {behavior}')\n\n            if behavior == 'initiate_engagement':\n                self.initiate_social_engagement(params)\n            elif behavior == 'maintain_engagement':\n                self.maintain_social_engagement(params)\n            elif behavior == 'terminate_engagement':\n                self.terminate_social_engagement(params)\n            elif behavior == 'greet_person':\n                self.greet_person(params)\n            elif behavior == 'follow_person':\n                self.follow_person(params)\n            else:\n                self.get_logger().warn(f'Unknown social behavior: {behavior}')\n\n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON in social command: {msg.data}')\n\n    def face_detection_callback(self, msg):\n        \"\"\"Handle face detection results\"\"\"\n        try:\n            faces_data = json.loads(msg.data)\n            faces = faces_data.get('faces', [])\n\n            if faces:\n                # Track the closest face\n                closest_face = min(faces, key=lambda f: f.get('distance', float('inf')))\n                self.attended_person = closest_face\n                self.face_tracking_active = True\n            else:\n                self.face_tracking_active = False\n                if self.social_engagement_active:\n                    self.handle_person_lost()\n\n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON in face detection: {msg.data}')\n\n    def speech_recognition_callback(self, msg):\n        \"\"\"Handle speech recognition results\"\"\"\n        speech_data = msg.data  # In practice, this might be JSON\n\n        if self.social_engagement_active and self.attended_person:\n            # Add to conversation history\n            self.conversation_history.append({\n                'speaker': 'human',\n                'text': speech_data,\n                'timestamp': self.get_clock().now().nanoseconds / 1e9\n            })\n\n            # Respond appropriately\n            self.generate_social_response(speech_data)\n\n    def initiate_social_engagement(self, params: Dict[str, Any]):\n        \"\"\"Initiate social engagement with detected person\"\"\"\n        if self.attended_person:\n            distance = self.attended_person.get('distance', float('inf'))\n\n            if distance <= self.social_params['greeting_distance']:\n                self.social_engagement_active = True\n                self.get_logger().info('Social engagement initiated')\n\n                # Greet the person\n                self.greet_person(params)\n\n                # Turn to face them\n                self.turn_to_face_person()\n            else:\n                self.get_logger().info(f'Person too far for engagement: {distance:.2f}m')\n        else:\n            self.get_logger().info('No person detected for engagement')\n\n    def maintain_social_engagement(self, params: Dict[str, Any]):\n        \"\"\"Maintain active social engagement\"\"\"\n        if self.social_engagement_active and self.attended_person:\n            # Keep appropriate distance\n            distance = self.attended_person.get('distance', float('inf'))\n\n            if distance > self.social_params['personal_space'] * 2:\n                # Person moved away, follow if allowed\n                if params.get('should_follow', False):\n                    self.follow_person({'target_person': self.attended_person})\n            elif distance < self.social_params['personal_space']:\n                # Too close, move back\n                self.move_away_from_person()\n\n            # Maintain eye contact/gaze\n            self.maintain_gaze_contact()\n\n    def terminate_social_engagement(self, params: Dict[str, Any]):\n        \"\"\"Terminate social engagement\"\"\"\n        self.social_engagement_active = False\n        self.attended_person = None\n        self.face_tracking_active = False\n        self.conversation_history = []\n\n        self.get_logger().info('Social engagement terminated')\n\n    def greet_person(self, params: Dict[str, Any]):\n        \"\"\"Greet the detected person\"\"\"\n        greeting_type = params.get('greeting_type', 'standard')\n\n        greetings = {\n            'standard': 'Hello! How can I help you today?',\n            'formal': 'Good day. It is a pleasure to meet you.',\n            'informal': 'Hi there! What brings you here?'\n        }\n\n        greeting_text = greetings.get(greeting_type, greetings['standard'])\n\n        # Publish greeting to speech system\n        greeting_msg = String()\n        greeting_msg.data = greeting_text\n        greeting_pub = self.create_publisher(String, 'tts_input', 10)\n        greeting_pub.publish(greeting_msg)\n\n        self.get_logger().info(f'Greeting: {greeting_text}')\n\n    def follow_person(self, params: Dict[str, Any]):\n        \"\"\"Follow the specified person\"\"\"\n        target_person = params.get('target_person', self.attended_person)\n\n        if target_person:\n            # Calculate relative position\n            person_x = target_person.get('position_2d', {}).get('x', 0)\n            person_y = target_person.get('position_2d', {}).get('y', 0)\n\n            # Move to maintain appropriate following distance\n            cmd_vel = Twist()\n            cmd_vel.linear.x = 0.3  # Move forward\n            cmd_vel.angular.z = -person_x * 0.5  # Correct heading\n\n            self.cmd_vel_pub.publish(cmd_vel)\n\n            self.get_logger().info(f'Following person at position ({person_x:.2f}, {person_y:.2f})')\n\n    def turn_to_face_person(self):\n        \"\"\"Turn robot to face the attended person\"\"\"\n        if self.attended_person:\n            # Get person's position relative to robot\n            person_2d = self.attended_person.get('position_2d', {})\n            person_x = person_2d.get('x', 0)\n\n            # Turn head/eyes to look at person\n            head_control_msg = String()\n            head_control_msg.data = json.dumps({\n                'pan': person_x * 0.1,  # Adjust pan based on x position\n                'tilt': 0.0  # Keep level\n            })\n            self.head_control_pub.publish(head_control_msg)\n\n    def move_away_from_person(self):\n        \"\"\"Move away from person to maintain personal space\"\"\"\n        cmd_vel = Twist()\n        cmd_vel.linear.x = -0.2  # Move backward slowly\n        cmd_vel.angular.z = 0.0\n\n        self.cmd_vel_pub.publish(cmd_vel)\n\n    def maintain_gaze_contact(self):\n        \"\"\"Maintain appropriate gaze contact with person\"\"\"\n        if self.attended_person:\n            # Continue looking at person\n            self.turn_to_face_person()\n\n    def handle_person_lost(self):\n        \"\"\"Handle when attended person is no longer detected\"\"\"\n        if self.social_engagement_active:\n            # Wait briefly to see if person reappears\n            # In a real system, you might implement a search behavior\n            self.get_logger().info('Attended person no longer detected')\n\n    def generate_social_response(self, human_speech: str):\n        \"\"\"Generate appropriate social response to human speech\"\"\"\n        human_speech_lower = human_speech.lower()\n\n        # Simple response generation based on keywords\n        if any(word in human_speech_lower for word in ['hello', 'hi', 'hey']):\n            response = 'Hello! Nice to meet you.'\n        elif any(word in human_speech_lower for word in ['how are you', 'how are you doing']):\n            response = 'I am functioning well, thank you for asking!'\n        elif any(word in human_speech_lower for word in ['what', 'who', 'where']):\n            response = 'I am a humanoid robot designed to assist and interact with people.'\n        elif any(word in human_speech_lower for word in ['bye', 'goodbye', 'see you']):\n            response = 'Goodbye! It was nice talking with you.'\n            self.terminate_social_engagement({})\n        else:\n            response = 'I understand. How else can I help you?'\n\n        # Publish response to speech system\n        response_msg = String()\n        response_msg.data = response\n        response_pub = self.create_publisher(String, 'tts_input', 10)\n        response_pub.publish(response_msg)\n\n        # Add to conversation history\n        self.conversation_history.append({\n            'speaker': 'robot',\n            'text': response,\n            'timestamp': self.get_clock().now().nanoseconds / 1e9\n        })\n\n    def social_behavior_loop(self):\n        \"\"\"Main social behavior execution loop\"\"\"\n        status_msg = String()\n        status_data = {\n            'engagement_active': self.social_engagement_active,\n            'face_tracking': self.face_tracking_active,\n            'attended_person': self.attended_person is not None,\n            'conversation_length': len(self.conversation_history)\n        }\n        status_msg.data = json.dumps(status_data)\n        self.social_status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    social_behaviors = SocialInteractionBehaviors()\n\n    try:\n        rclpy.spin(social_behaviors)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        social_behaviors.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"integration-and-testing",children:"Integration and Testing"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="capstone_integration_test.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nimport json\nimport time\nfrom typing import Dict, Any\n\nclass CapstoneIntegrationTest(Node):\n    def __init__(self):\n        super().__init__('capstone_integration_test')\n\n        # Publishers\n        self.task_command_pub = self.create_publisher(\n            String, 'capstone_task_command', 10)\n        self.complex_behavior_pub = self.create_publisher(\n            String, 'complex_behavior_command', 10)\n        self.social_behavior_pub = self.create_publisher(\n            String, 'social_behavior_command', 10)\n\n        # Test execution\n        self.test_timer = self.create_timer(5.0, self.run_next_test)\n        self.test_sequence = [\n            self.test_guided_tour,\n            self.test_object_search,\n            self.test_social_interaction,\n            self.test_adaptive_behavior\n        ]\n        self.current_test_index = 0\n\n    def run_next_test(self):\n        \"\"\"Run the next test in sequence\"\"\"\n        if self.current_test_index < len(self.test_sequence):\n            test_func = self.test_sequence[self.current_test_index]\n            self.get_logger().info(f'Running test {self.current_test_index + 1}: {test_func.__name__}')\n\n            try:\n                test_func()\n                self.current_test_index += 1\n            except Exception as e:\n                self.get_logger().error(f'Test {test_func.__name__} failed: {e}')\n                self.current_test_index += 1\n        else:\n            self.get_logger().info('All integration tests completed')\n            self.test_timer.cancel()\n\n    def test_guided_tour(self):\n        \"\"\"Test guided tour behavior\"\"\"\n        task_command = {\n            'type': 'navigate_and_interact',\n            'parameters': {\n                'location': 'kitchen'\n            }\n        }\n\n        msg = String()\n        msg.data = json.dumps(task_command)\n        self.task_command_pub.publish(msg)\n\n        self.get_logger().info('Guided tour test initiated')\n\n    def test_object_search(self):\n        \"\"\"Test object search behavior\"\"\"\n        behavior_command = {\n            'behavior': 'object_search',\n            'parameters': {\n                'object': 'cup'\n            }\n        }\n\n        msg = String()\n        msg.data = json.dumps(behavior_command)\n        self.complex_behavior_pub.publish(msg)\n\n        self.get_logger().info('Object search test initiated')\n\n    def test_social_interaction(self):\n        \"\"\"Test social interaction\"\"\"\n        social_command = {\n            'behavior': 'initiate_engagement',\n            'parameters': {\n                'greeting_type': 'standard'\n            }\n        }\n\n        msg = String()\n        msg.data = json.dumps(social_command)\n        self.social_behavior_pub.publish(msg)\n\n        self.get_logger().info('Social interaction test initiated')\n\n    def test_adaptive_behavior(self):\n        \"\"\"Test adaptation system\"\"\"\n        # Send experience data to trigger adaptation\n        experience_data = {\n            'behavior': 'object_search',\n            'outcome': 'failure',\n            'context': {'lighting': 0.2, 'object_size': 0.05},\n            'performance': 0.3\n        }\n\n        experience_pub = self.create_publisher(String, 'behavior_experience', 10)\n        msg = String()\n        msg.data = json.dumps(experience_data)\n        experience_pub.publish(msg)\n\n        self.get_logger().info('Adaptive behavior test initiated')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    integration_test = CapstoneIntegrationTest()\n\n    try:\n        rclpy.spin(integration_test)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        integration_test.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"best-practices-for-autonomous-behavior",children:"Best Practices for Autonomous Behavior"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Modularity"}),": Design behaviors as independent, testable modules"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Safety"}),": Implement safety checks and fallback behaviors"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Adaptability"}),": Include learning and adaptation mechanisms"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Monitoring"}),": Continuously monitor behavior execution"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Testing"}),": Extensive testing in simulation before deployment"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"The capstone project demonstrates the integration of all components learned throughout the course. Autonomous behavior implementation requires careful coordination between perception, cognition, and action systems. The humanoid robot system showcases how Vision-Language-Action models can enable sophisticated human-robot interaction and task execution. Success depends on robust system integration, adaptive learning mechanisms, and careful attention to safety and reliability."}),"\n",(0,a.jsx)(o.A,{title:"Autonomous Behavior Architecture",description:"Shows the architecture of autonomous behaviors in the humanoid robot system"})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}}}]);